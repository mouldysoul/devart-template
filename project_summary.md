# Project Title
The self learning tangled hierarchy feedback loop

## Authors
- Insert main author name, surname, github account
- Insert other author(s) name, surname, github account (one per list element)

## Description
The idea of this project is to create a musical instruent that learns how the user wants it to be played. The project uses an IR motion detector to measure movements in position and distance of hands and outputs Midi note values to be fed into a synthesiser. A neural net is to be implemented to help associate gestures to trained interval or chord progression nets, for example a user could train a neural net by rewarding it for pleasent intervals or chord progressions, this data could then be used to attach on to certain gestures. No knowledge would be required to play this instrument only an ability to move one's hand. There is also an element of real-time visual feedback courtesy of a projector pointing at a screen and the angles of camera planes manipulated by distance/postion info from IR device. 


## Link to Prototype

Noise:

http://www.youtube.com/watch?v=KLh4ZvrgDxE

Visuals:

http://www.youtube.com/watch?v=458uyit28Ps

[Example Link](http://www.google.com "Example Link")

## Example Code
NOTE: Wrap your code blocks or any code citation by using ``` like the example below.
```
function test() {
  console.log("Printing a test");
}
```
## Links to External Libraries
 NOTE: You can also use this space to link to external libraries or Github repositories you used on your project.

[Example Link](http://www.google.com "Example Link")

## Images & Videos
NOTE: For additional images you can either use a relative link to an image on this repo or an absolute link to an externally hosted image.

![Example Image](project_images/cover.jpg?raw=true "Example Image")

https://www.youtube.com/watch?v=30yGOxJJ2PQ
